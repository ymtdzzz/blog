#+HUGO_BASE_DIR: ./
#+HUGO_SECTION: posts
#+author: zeroclock

* Blog entries
  :PROPERTIES:
  :VISIBILITY: children
  :END:
** DONE Goのhot reloadにgo-taskを使ってみる                  :go:task:docker:
   :PROPERTIES:
   :EXPORT_FILE_NAME: using-ga-task-to-host-reload
   :EXPORT_HUGO_SECTION: /posts/2020/07
   :EXPORT_DATE: 2020-07-08
   :EXPORT_HUGO_CUSTOM_FRONT_MATTER+: :toc true
   :END:
*** Goでhot reloading
    作っているアプリのサーバサイドをGOで書いているので、[[https://github.com/oxequa/realize][Realize]]でhot reloadを実現しようと思ったのですが、 ~GO111MODULE=off~ にしないとgo getできなかったり、いざdocker-composeで ~realize start --run~ しようとすると下記のようなエラーが出たりと色々あれだったので、他に使えそうなパッケージが無いか探してみました。

    #+CAPTION: docker-composeでrealize startした際のエラー
    #+BEGIN_SRC
...
[01:09:01][SRC] : Running..
panic: runtime error: invalid memory address or nil pointer dereference
[signal SIGSEGV: segmentation violation code=0x1 addr=0x0 pc=0x4cf2fb]

goroutine 8768 [running]:
os.(*Process).signal(0x0, 0xad7a20, 0xe34878, 0x0, 0x0)
	/usr/local/go/src/os/exec_unix.go:56 +0x3b
os.(*Process).Signal(...)
	/usr/local/go/src/os/exec.go:131
github.com/oxequa/realize/realize.(*Project).run.func1(0xc000175698)
	/go/src/github.com/oxequa/realize/realize/projects.go:581 +0x5c
github.com/oxequa/realize/realize.(*Project).run(0xc0001fa000, 0xc000133ab8, 0x7, 0xc000342300, 0xc000110540, 0xad2c20, 0xc00011c8d0)
	/go/src/github.com/oxequa/realize/realize/projects.go:646 +0xc2d
github.com/oxequa/realize/realize.(*Project).Reload.func3(0xc0001fa000, 0xc000342300, 0xc000110540)
	/go/src/github.com/oxequa/realize/realize/projects.go:262 +0x147
created by github.com/oxequa/realize/realize.(*Project).Reload
	/go/src/github.com/oxequa/realize/realize/projects.go:260 +0x297
    #+END_SRC

    調べたところ、[[https://github.com/go-task/task][go-task]] が中々シンプルで良さそうだったので試してみました。

*** go-taskの使い方
    基本的な使い方は下記の通り。

**** go-taskのインストール
     [[https://taskfile.dev/#/installation][ドキュメント]] にあるように、MacとLinux(Linuxbrew導入済)は =brew= で、Windowsの場合は =scoop= とかでサクッとインストールできるみたいです。

     ただ、私の場合はdocker上のdebianでインストールしたかったので +dockerでlinuxbrew入れるの地味にめんどうなので+ バイナリを =dpkg= でインストールしました。

     #+caption: Debianにおいて、バイナリ(.deb)をdpkgでインストールするコマンド
     #+BEGIN_SRC bash
wget https://github.com/go-task/task/releases/download/v2.8.1/task_linux_amd64.deb
dpkg -i task_linux_amd64.deb
rm task_linux_amd64.deb
     #+END_SRC

**** Taskfile.ymlの作成
     go-taskでは諸々の設定をTaskfile.ymlに記述しますので、プロジェクトルートにTaskfile.ymlを作成します。 =task init= でサクッと作ってくれます。

     #+BEGIN_SRC bash
cd /path/to/project/root
task init
     #+END_SRC

     ソースをウォッチして特定のコマンド（go runとか）を実行させたい場合、こんな感じに書けます

     #+BEGIN_SRC yaml
version: '2'

tasks:
  run:
    cmds:
      - go run main.go
    sources:
      - ./**/*
     #+END_SRC

**** 実行
     あとはTaskfile.ymlがあるディレクトリで実行するだけです。

     #+BEGIN_SRC bash
# runはTaskfile.ymlで指定したタスク名
task run
     #+END_SRC
*** 自分の使い方
    プレイベートで開発しているアプリが、Goで書いたローカルサーバでReactを配信する　といった構成になってます。Goのサーバはリソース配信用とAPI兼用になっており、開発中はDocker container上で動かします。シンプルな構成なのでついでに記載しておきます。

    フォルダ構成（抜粋）は下記の通り。

    #+BEGIN_SRC plantuml :file overview.png :cache yes :cmdline -config "$HOME/.emacs.d/styles.uml" :async
@startsalt
{
{T
+src
++web
+++src
+++public
+++node_modules
+++build
+++package.json
++main.go
++handler
+++router.go
+++middleware.go
++config
++startup.sh
++Taskfile.yml
++Dockerfile
++docker-compose.yml
}
}
@endsalt
    #+END_SRC

    #+caption: プロジェクトのフォルダ構成（一部抜粋）
    #+RESULTS[47167a60cfd3c4776dd5c164046eb37355045db1]:
    [[file:overview.png]]

**** Dockerfile
     npmも入れています。

     #+BEGIN_SRC Dockerfile
FROM golang:1.14.4

WORKDIR /go/src

ENV GO111MODULE=on

pCOPY . /go/src

RUN apt-get update \
    && apt-get install -y git python jq curl \
    && curl -sL https://deb.nodesource.com/setup_14.x | bash - \
    && apt-get update && apt-get install -y nodejs \
    && npm install yarn -g \
    && wget https://github.com/go-task/task/releases/download/v2.8.1/task_linux_amd64.deb \
    && dpkg -i task_linux_amd64.deb \
    && rm task_linux_amd64.deb

EXPOSE 8080

CMD ["task", "run"]
     #+END_SRC

**** Taskfile
     #+BEGIN_SRC yaml
version: '2'

tasks:
  run:
    cmds:
      - cmd: kill -TERM `cat pidfile`
        ignore_error: true
      - go run main.go --pid-file=pidfile
    sources:
      - ./**/*
     #+END_SRC

     =go run main.go= だけだとフォルダ変更を検知する度に前に走っていたプロセスを落とさずにまた別プロセスとして起動してしまうので、pidを適当にどこかに吐き出しておいて、起動時は前のプロセスをkillしてから実行するようにしています（[[https://qiita.com/croquette0212/items/dab91c1075c1f3ac7b8d][go-taskでサーバーのライブリロードを実現する]] を参考にさせていただきました）。

     これでファイル変更を検知してホットリロードしてくれます。

**** 所感
     環境構築というプロジェクトの本質に関わらない部分については、なるべくエネルギーを割きたくないのですが、go-taskのおかげで自分が作りたいものに集中できています。

     実行済タスクのkillの仕方は若干ゴリっぽい側面があるので、もうちょいスマートにいけないか考え中です。ただ、Taskfile作ってコマンド叩くだけでいいというシンプルなワークフローは気に入ったので、しばらく使ってみたいと思います。
** DONE 【Typescript】axiosのレスポンスはきちんと型チェックしよう :typescript:axios:
   :PROPERTIES:
   :EXPORT_FILE_NAME: type-checking-the-response-via-axios
   :EXPORT_HUGO_SECTION: /posts/2020/08
   :EXPORT_DATE: 2020-08-12
   :EXPORT_HUGO_CUSTOM_FRONT_MATTER: :toc true
   :END:
*** Axiosでエラー
    Axiosで外部APIを叩いてデータを取得したいと思い、下記のコードを書いたとします。

    #+caption: AxiosでAPIを叩いて情報を取得するコード例
    #+BEGIN_SRC typescript
import axios, { AxiosPromise } from "axios";

interface CatApiResponse {
  name: string;
  age: number;
  parents: string[];
}

const client = axios.create({
  baseURL: "https://example.com/api/v2/",
  headers: {
    "Content-Type": "application/json"
  }
});

const fetchAllCat = (): AxiosPromise<CatApiResponse> => client.get("cat");

const hoge = () => {
  const data = fetchAllCat();
  data.then((data) => {
    data.data.parents.map((parent) => {
      console.log(parent);
      return "hoge";
    });
  });
};
    #+END_SRC

    IDEで型推定を確認すると、確かに ~CatApiResponse~ になっている。

    #+DOWNLOADED: clipboard @ 2020-08-12 17:55:51
    #+CAPTION: レスポンスデータの型推定
    [[file:blog.org_imgs/20200812_175551.png]]

    けど、実際はnullかもしれないし、 ~CatApiResponse~ のinterfaceに則したデータ構造じゃないかもしれない。で、実際に変なデータを返すAPIを用意して実行すると、案の定 ~data.data.parents.map()~ のところでコケる。でも、IDEにも怒られないし、コンパイル時にもツッコまれない。

*** カスタム型ガードでちゃんとチェックする
    イマイチ釈然としないけど、型ガードでちゃんとデータをチェックしてから返却しよう　というお話。

    #+caption: CatApiResponseの型ガード例
    #+BEGIN_SRC typescript
const isCatApiResnpose = (arg: any): arg is CatApiResponse => {
  return (arg.name !== undefined
    && arg.age !== undefined
    && arg.parents !== undefined
    && Array.isArray(arg.parents))
}
    #+END_SRC

    こんな感じの型ガードを書いてあげて、 ~fetchAllCat()~ で受け取ったPromiseをresolveしたときに、きちんとデータがCapApiResponseのinterfaceに準拠していることを確認してあげる必要がある。

    #+caption: きちんと型チェックを行う例
    #+BEGIN_SRC typescript
const hoge = () => {
  const data = fetchAllCat();
  data.then((data) => {
    if (isCatApiResnpose(data.data)) {
      data.data.parents.map((parent) => {
        console.log(parent);
        return "hoge";
      });
    }
  });
};
    #+END_SRC

    こうすることで、はちゃめちゃなデータが返ってきても安全に処理ができる（これでいいのか...?）。

    実際はReactでデータをstateにsetしたりすることもあるが、その際はnullとか想定外のデータ構造だった場合は空のCatApiResponseを準備して返して上げれば単なる「データ無し」として扱える。

    で、ここで面倒なのが、「空のhoge interfaceのデータ」を作ることで、構造が複雑だと一々手動でemptyHogeDataみたいなものを作らないといけない。ただ、その場合は該当するinterfaceを実装したclassを作っちゃって、そのconstructorで空を作らせるのも手かな　と。


    ということで、今回はtypescriptのお話でございました。
    
** TODO TauriでWebの技術でネイティブアプリを作る                      :tauri:
   :PROPERTIES:
   :EXPORT_FILE_NAME: building-native-app-with-tauri
   :EXPORT_HUGO_SECTION: /posts/2020/07
   :EXPORT_DATE: 2020-07-10
   :EXPORT_HUGO_CUSTOM_FRONT_MATTER: :toc true
   :END:
** DONE EmacsのLSP-modeの動作を軽くする           :Emacs:lspmode:performance:
   :PROPERTIES:
   :EXPORT_FILE_NAME: emacs-lsp-mode-more-faster
   :EXPORT_HUGO_SECTION: /posts/2020/07
   :EXPORT_DATE: 2020-07-11
   :EXPORT_HUGO_CUSTOM_FRONT_MATTER: :toc true
   :END:
   EmacsのLSP-modeは非常に快適で、言語サポートの追加も簡単にできるので重宝しているのですが、動作がカクついたりしてストレスになる場合がありました。[[https://emacs-lsp.github.io/lsp-mode/page/performance/][ドキュメント]]を確認したところ、パフォーマンスチューニングの方法があったのでまとめておきます。

*** いざチューニング
    今回対応するチューニングが正常に適用されているかどうかは、 =M-x lsp-diagnose= で確認できます。

    #+caption: lsp-diagnoseの出力結果
    #+BEGIN_SRC
Checking for Native JSON support: OK
Checking emacs version has `read-process-output-max': OK
Using company-capf: OK
Check emacs supports `read-process-output-max': ERROR
Check `read-process-output-max' default has been changed from 4k: ERROR
Byte compiled against Native JSON (recompile lsp-mode if failing when Native JSON available): ERROR
`gc-cons-threshold' increased?: ERROR
    #+END_SRC

    以前company-capfだけ有効化していたので、 ~Using company-capf~ がOKになっていますが、company-lspを使用している場合はERRORになるかと思います。

    また、私の環境はEmacs-plus@28でネイティブJSONパーサ（後述）入りでビルドしたものなので、 =Native JSON support= と =emacs version has `read-process-ourput-max`= がOKになっています。Emacs26とかだとERRORになるかもしれませんので、アップデートが必要です。

    それでは実際に各チューニング内容を確認していきます。

**** EmacsのネイティブJSONパーサを使う
     Emacsはver.27以降は、ネイティブでJSONのパースをサポートするようになりました。

     ただし、ver.27以降でも、コンパイル時に =--with-json= オプションが渡されていないとサポートされないみたいです。

     自分が使用しているEmacsが対応しているかどうかは =M-: (functionp 'json-serialize)= で確認できます。

     ちなみに、MacでEmacs-plusを使用する場合は、 =brew install emacs@28 --with-jansson= でインストールできます。

     Elispのパーサよりも、ネイティブパーサの方が最大15倍程度まで高速化されるらしい(Benchmarks show that Emacs 27 is ~15 times faster than Emacs when using Elisp json parser implementation.)ので、この設定は絶対ON推奨です。

**** gc-cons-threshold の調整
     =gc-cons-threshold= は、ガベージコレクションを実行する閾値ですが、デフォルト設定だとLSP-server/client間のデータやり取りに対して少なすぎるため、増やしてあげる必要があります。

     調製の仕方は下記の２通り紹介されていました。

     - 100mbくらいの大きな値をドカッと割り当てる（doomとかspacemacsとかも同じような設定）
     - 初期設定を２倍していき、２倍してもレスポンスに変化が見られない時点で増加をストップさせ、それを設定値とする

     後者の設定方法についてはGNU EmacsのメンテナであるEli Zaretskii氏のおすすめなので、一旦はこれに従って設定しました。

     現在の設定値を確認するためには =M-x eval-expression gc-cons-threshold= で確認できます。ちなみに私の環境だと800,000(80KB)でした。

     毎回init.elを書き換えて増やしていくのはめんどうなので、 =M-x eval-expression (seta gc-cons-threshold 1600000)= のような感じで少しずつ増やして様子を見てみたところ、丁度6,400,000と12,800,000の辺りでサジェストの出方がスムーズになり、それ以上増やしてもそこまで変化が無かったので、12,800,000(12MB)あたりにしておきました。

**** company-lsp ではなく company-capf を使用する
     今はcompany-lspは非推奨になっているので、company-capfを使用する設定を行います。

     ドキュメントだと =(setq lsp-prefer-capf t)= だけでいいとのことだったのですが、私の環境だとcompany-backendsにcompany-capfが入ってくれなかったので、 下記のように明示的に設定しています（use-packageでlsp-mode読み込んでるとこ）。

     #+caption: 明示的にcompany-capfを使用する設定
     #+begin_src elisp
  :hook
  (lsp-mode . lsp-ui-mode)
  (lsp-managed-mode . (lambda () (setq-local company-backends '(company-capf))))
     #+end_src

     設定の確認は =M-x company-diag= でできます。

**** (Windowsの場合)lsp-uiを無効化する
     Windowsだとlsp-uiが悪さをして遅くなることがあるみたいです。私はMacなのでスルー。

**** lsp-idle-delay の調整
     タイピング中にどれくらいの頻度でLSP系の状態（ハイライトとか）を更新するかの値ですが、これはとりあえず初期値の0.5のままにしました。

*** 最終確認
    以上のチューニング完了後、再び =lsp-diagnose= を実行すると、下記のような出力になるかと思います。

    #+caption: やったぜ
    #+begin_src
Checking for Native JSON support: OK
Checking emacs version has `read-process-output-max': OK
Using company-capf: OK
Check emacs supports `read-process-output-max': OK
Check `read-process-output-max' default has been changed from 4k: OK
Byte compiled against Native JSON (recompile lsp-mode if failing when Native JSON available): OK
`gc-cons-threshold' increased?: OK
    #+end_src

** DONE Lambciとimg2lambdaとserverlessでLambdaのデプロイフローを構築する :AWS:Lambda:lambci:img2lambda:PHP:CustomRuntime:serverless:
   :PROPERTIES:
   :EXPORT_FILE_NAME: deploy-lambda-with-lambci-img2lambda-serverless
   :EXPORT_HUGO_SECTION: /posts/2020/09
   :EXPORT_DATE: 2020-09-02
   :EXPORT_HUGO_CUSTOM_FRONT_MATTER: :toc true
   :END:
*** Lambdaのローカル環境
    これまでLambdaを構築する際には、ソースコードを決め打ちで書いてzipで上げたり、コンソール上のエディタでポチポチ開発していたりしてました。

    PythonとかNodejsとかなら、それでも簡単なAPIくらいなら作れるのですが、ちょっと複雑なことになったり、PHPみたいにCustom Runtimeを使いたい場合とかは、何度もデプロイし直してトライアンドエラーするのは効率が悪いです。

    やっぱり、他のソースと同じようにローカルでガリガリ書いて、コマンドで自動デプロイができた方が良いので色々探したところ、Lambciとimg2lambda（あとserverless）を使ったフローが良さそうだったので紹介します。

    <!--more-->
*** lambciとimg2lambda
    はじめに、各ツールの概要を軽く説明します。

**** lambci/lambda
     [[https://hub.docker.com/r/lambci/lambda/][lambci/lambda]] は、Lambdaの環境に非常に近いDockerイメージです。PythonのようなLambdaでデフォルトでサポートしている言語であれば、このイメージをPullしてファイルを配置するだけでLambdaのローカル開発環境がサクッと作れちゃいます。

     PHPの場合はCustom Runtimeを作成すれば問題無く動作します（今回の記事で解説）。

**** img2lambda
     [[https://github.com/awslabs/aws-lambda-container-image-converter][AWS Lambda Container Image Converter(略してimg2lambda)]] は、Dockerコンテナ上のソースコードをLambdaにデプロイ可能なzipファイルに固めてくれるツールです。

     配置するコードは下記のルールに従います。

#+BEGIN_QUOTE
     - /var/task : Lambdaのソースコード本体
     - /opt : Lambdaレイヤー
#+END_QUOTE

     よって、 ~/opt~ 配下にPHPを動かすためのバイナリとかライブラリ系を配置すれば、Custom Runtimeであってもきちんと固めてくれます。

**** Serverless Framework
     おなじみの [[https://www.serverless.com/][serverless framework]] ですが、これは、作成したyamlテンプレートの通りに自動デプロイしてくれるツールです。構成情報をコード化して管理する　という面ではCloudFormationと同じですが、もっと手軽に記述することができます（serverlessがCloudFormationに変換してくれる）。

     今回は、img2lambdaで固めたzipとテンプレートファイルをインプットにして、コマンド一発でデプロイするのに使用します。

*** 全体像
    流れを図式化すると、下記のような感じです。

#+DOWNLOADED: clipboard @ 2020-09-01 21:04:18
#+CAPTION: 全体の流れ
[[file:blog.org_imgs/20200901_210418.png]]

    ローカルで開発したイメージをそのままLambdaにデプロイできるので、スムーズにLambdaの開発を行うことができます。

*** 実際に作ってみる
    今回は、カスタムランタイムを使いたいのでPHPでやってみたいと思います。

**** lambciによるローカル開発環境のセットアップ
     まずは適当にディレクトリを作ってもらって、Dockerfileを作成します。といっても、基本的なところはimg2lambdaのexampleとほぼ同じです。

#+BEGIN_SRC dockerfile
#+CAPTION: Dockerfile
# Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.
# SPDX-License-Identifier: MIT-0

####### PHP custom runtime #######
####### Install and compile everything #######
# Same AL version as Lambda execution environment AMI
FROM amazonlinux:2018.03.0.20190514 as builder

# Set desired PHP Version
ARG php_version="7.3.6"

# Lock to 2018.03 release (same as Lambda) and install compilation dependencies
RUN sed -i 's;^releasever.*;releasever=2018.03;;' /etc/yum.conf && \
    yum clean all && \
    yum install -y autoconf \
                bison \
                bzip2-devel \
                gcc \
                gcc-c++ \
                git \
                gzip \
                libcurl-devel \
                libxml2-devel \
                make \
                openssl-devel \
                tar \
                unzip \
                zip

# Download the PHP source, compile, and install both PHP and Composer
RUN curl -sL https://github.com/php/php-src/archive/php-${php_version}.tar.gz | tar -xvz && \
    cd php-src-php-${php_version} && \
    ./buildconf --force && \
    ./configure --prefix=/opt/php-7-bin/ --with-openssl --with-curl --with-zlib --without-pear --enable-bcmath --with-bz2 --enable-mbstring --with-mysqli && \
    make -j 5 && \
    make install && \
    /opt/php-7-bin/bin/php -v && \
    curl -sS https://getcomposer.org/installer | /opt/php-7-bin/bin/php -- --install-dir=/opt/php-7-bin/bin/ --filename=composer

# Prepare runtime files
RUN mkdir -p /lambda-php-runtime/bin && \
    cp /opt/php-7-bin/bin/php /lambda-php-runtime/bin/php

COPY runtime/bootstrap /lambda-php-runtime/
RUN chmod 0555 /lambda-php-runtime/bootstrap

RUN /opt/php-7-bin/bin/php /opt/php-7-bin/bin/composer config -g repos.packagist composer https://packagist.jp
RUN /opt/php-7-bin/bin/php /opt/php-7-bin/bin/composer config -g secure-http false

# Install Guzzle, prepare vendor files
RUN mkdir /lambda-php-vendor && \
    cd /lambda-php-vendor && \
    /opt/php-7-bin/bin/php /opt/php-7-bin/bin/composer require guzzlehttp/guzzle && \
    /opt/php-7-bin/bin/php /opt/php-7-bin/bin/composer require aws/aws-sdk-php

###### Create runtime image ######

FROM lambci/lambda:provided as runtime

# Layer 1
COPY --from=builder /lambda-php-runtime /opt/

# Layer 2
COPY --from=builder /lambda-php-vendor/vendor /opt/vendor

###### Create function image ######

FROM runtime as function

COPY function/hello /var/task/src/
#+END_SRC

    続いて、docker-compose.yamlを作成します。コンテナ一つでも楽なのでいつもdocker-compose使ってます。

#+BEGIN_SRC yaml
#+CAPTION: docker-compose.yaml
version: '3'
services:
  lambda_hello:
    build: .
    tty: true
    working_dir: /var/task/src
    ports:
      - 9001:9001
    volumes:
      - ./function/hello:/var/task/src:delegated
    environment:
      DOCKER_LAMBDA_WATCH: 1
      DOCKER_LAMBDA_STAY_OPEN: 1
      DOCKER_LAMBDA_API_PORT: 9001
      TEST_ENV_VAR: "hello world!"
    command: hello
#+END_SRC

     function/hello/hello.phpを作成して、Lambda関数本体を作成します。環境変数からデータを取得して返却するだけの処理です。

#+BEGIN_SRC php
#+CAPTION: function/hello/hello.php
<?php

function hello($data)
{
    $data = json_decode($data['body'], true);
    $text = getenv('TEST_ENV_VAR');
    $param = (isset($data['param'])) ? $data['param'] : '山田 太郎'; 
    $response = [
        'statusCode' => 200,
        'body' => $text . ' ' . $param . 'さん',
    ];
    return $response;
}
#+END_SRC

     次に、runtime/bootstrapを作成します。これは、Lambdaで取得したリクエストを取得して、パラメータをhandler（今回はhello.php）に渡し、返却されたデータをレスポンスとして返却しています。

     http通信周りはGuzzleを使用しているので、コード自体は44step程度しかないです。

#+BEGIN_SRC php
#+CAPTION: runtime/bootstrap
#!/opt/bin/php
<?php

// Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.
// SPDX-License-Identifier: MIT-0

// This invokes Composer's autoloader so that we'll be able to use Guzzle and any other 3rd party libraries we need.
require __DIR__ . '/vendor/autoload.php';

function getNextRequest()
{
    $client = new \GuzzleHttp\Client();
    $response = $client->get('http://' . $_ENV['AWS_LAMBDA_RUNTIME_API'] . '/2018-06-01/runtime/invocation/next');

    return [
      'invocationId' => $response->getHeader('Lambda-Runtime-Aws-Request-Id')[0],
      'payload' => json_decode((string) $response->getBody(), true)
    ];
}

function sendResponse($invocationId, $response)
{
    $client = new \GuzzleHttp\Client();
    $client->post(
      'http://' . $_ENV['AWS_LAMBDA_RUNTIME_API'] . '/2018-06-01/runtime/invocation/' . $invocationId . '/response',
      ['body' => json_encode($response)]
    );
}

// This is the request processing loop. Barring unrecoverable failure, this loop runs until the environment shuts down.
do {
    // Ask the runtime API for a request to handle.
    $request = getNextRequest();

    // Obtain the function name from the _HANDLER environment variable and ensure the function's code is available.
    $handlerFunction = array_slice(explode('.', $_ENV['_HANDLER']), -1)[0];
    require_once $_ENV['LAMBDA_TASK_ROOT'] . '/src/' . $handlerFunction . '.php';

    // Execute the desired function and obtain the response.
    $response = $handlerFunction($request['payload']);

    // Submit the response back to the runtime API.
    sendResponse($request['invocationId'], $response);
} while (true);
#+END_SRC

     さて、これでdocker-composeを起動してみます。

#+BEGIN_SRC bash
#+CAPTION: docker-compose起動
$ docker-compose up -d
#+END_SRC

     PHPをソースからビルドするので初回起動のイメージビルド時は若干時間がかかります。

     コンテナが起動したら、軽く動作確認します。

#+begin_src bash
#+caption: 動作確認
$ curl -d '{}' http://localhost:9001/2015-03-31/functions/hello/invocations
{"statusCode":200,"body":"hello world! \u5c71\u7530 \u592a\u90ce\u3055\u3093"}
#+end_src

     ちゃんと期待通り動作してますね。ちょっと補足ですが、デプロイ先の環境はAPI Gatewayのプロキシ統合を使用するので、レスポンスパターンはきちんと合わせます。

     ローカルだとresponseCodeを400とかに設定してもAPIを叩くと200になってしまいますが、デプロイされるときちんと400になります（このあたりの差分をローカルでもきちんと吸収したいけどイマイチ解決策が見つからず・・・）。

     また、リクエストパラメータについても、API Gatewayを通るとJSONオブジェクトのbodyパラメータにテキストでエンドユーザが送ったパラメータが格納されるので注意です。
     
**** img2lambdaでデプロイパッケージを作成する
     さて、ここまでくると下記のようなディレクトリ構成になっているかと思います。

     #+begin_src plantuml :file overview.svg :cache yes :cmdline -config "$HOME/.emacs.d/styles.uml" :async
@@startsalt
{
  {T
   + project_root
   ++ Dockerfile
   ++ docker-compose.yaml
   ++ function
   +++ hello
   ++++ hello.php
   ++ runtime
   +++ bootstrap
  }
}
@@endsalt
     #+end_src

     #+caption: 現在のディレクトリ構成
     #+RESULTS[d80c487c05e65b3c3eb35f5a261f4ced9448a97f]:
     [[file:overview.svg]]

     インストールは、[[https://github.com/awslabs/aws-lambda-container-image-converter/releases][GithubのReleaseページ]] から、それぞれのプラットフォーム用のバイナリをダウンロードしてパスが通ってるところに配置するだけです。

#+begin_src bash
#+caption: img2lambdaのインストール確認
$ img2lambda --version
img2lambda version 1.2.4 (1d7760a)
#+end_src

     これでローカルのDockerコンテナをデプロイパッケージに固める準備ができたので、下記のコマンドをプロジェクトルートディレクトリで実行します。

#+begin_src bash
$ img2lambda -i lambci_lambda_hello:latest -r ap-northeast-1 -o ./output
2020/09/02 08:58:29 Parsing the image docker-daemon:lambci_lambda_hello:latest
2020/09/02 08:58:58 Image docker-daemon:lambci_lambda_hello:latest has 5 layers
...
2020/09/02 09:00:07 Lambda layer ARNs (2 total) are written to output/layers.json and output/layers.yaml
#+end_src

**** serverlessで自動デプロイする
     デプロイパッケージの準備ができたので、serverlessで自動デプロイします。

     deploy/serverless.ymlを作成し、下記のように記述します。

#+begin_src yaml
service: Lambda

provider:
  name: aws
  runtime: provided
  region: ap-northeast-1

package:
  individually: true

functions:
  LambciHello:
    handler: hello
    package:
      artifact: ../output/function.zip
    layers:
      ${file(../output/layers.json)}
    events:
      - http:
          path: /hello
          method: post
    environment:
      TEST_ENV_VAR: "hello from lambda!"
#+end_src

     それではデプロイしてみます（ ~aws configure~ とかはやっといてね）。

#+begin_src bash
$ cd deploy
$ sls deploy
#+end_src

     正常に完了すると、きちんとLambdaとAPI Gatewayが作成されていることがわかります。

#+DOWNLOADED: clipboard @ 2020-09-02 09:13:37
#+CAPTION: デプロイ結果
[[file:blog.org_imgs/20200902_091337.png]]

     実際にPOSTしてみると、たしかに期待通りのレスポンスが返ってきています。

#+begin_src bash
$ curl -d '{}' https://*********.execute-api.ap-northeast-1.amazonaws.com/dev/hello
hello from lambda! 山田 太郎さん

$ curl -d '{"param": "田中 次郎"}' https://*********.execute-api.ap-northeast-1.amazonaws.com/dev/hello
hello from lambda! 田中 次郎さん
#+end_src

**** おわりに
     今の所上記のようなフローで開発が進めていますが、ローカルでAPI Gatewayのプロキシ統合がシミュレートできない点についてはもう少し改善の余地があるかなーと思います。

     現状、環境によって下記のようにエスケープしないといけないので・・・。

***** ローカル
#+begin_src json
{
    "body": "{\r\n\"param\": \"aiueo\"\r\n}"
}
#+end_src

***** Lambda
#+begin_src json
{
    "param": "aiueo"
}
#+end_src

     まあ、そこを除けば良いフローかと思います。

     そのうち、SAMのローカル環境とかも試してみたい。
** DONE 【Rust】as_bytes()でcannot borrow as mutable(E0596)エラー :Rust:trouble_shooting:
   :PROPERTIES:
   :EXPORT_FILE_NAME: rust-array-from-as-bytes-mutable-error
   :EXPORT_HUGO_SECTION: /posts/2020/10
   :EXPORT_DATE: 2020-10-30
   :EXPORT_HUGO_CUSTOM_FRONT_MATTER: :toc true
   :END:
*** cannot borrow data in a `&` reference as mutable
    共通鍵関連で、DES暗号化をRustで実装しているんですが、そのときにちょっとハマりかけたのでメモ。
    <!--more-->

#+CAPTION: 問題となったコード
#+BEGIN_SRC rust
fn main() {
    let mut src = "abc".to_string();
    let mut s = src.as_bytes();
    
    println!("{:08b}", &s[0]);
    set_bit(&mut s, 0);
    println!("↓");
    println!("{:08b}", &s[0]);
}

fn set_bit(bytes: &mut [u8], bit: usize) {
    bytes[bit / 8 as usize] |= 0x80 >> (bit % 8);
}
#+END_SRC

処理自体は単純で、文字列をbyte配列に変換後、指定されたビットを立てるような感じです。

ただ、このソースをコンパイルしようとすると、下記のようなエラーが発生します。

#+caption: エラー内容
#+BEGIN_SRC
error[E0596]: cannot borrow data in a `&` reference as mutable
 --> src/main.rs:8:13
  |
8 |     set_bit(&mut s, 0);
  |             ^^^^^^ cannot borrow as mutable
#+END_SRC

*** 原因
    [[https://moshg.github.io/rust-std-ja/std/primitive.str.html#method.as_bytes][as_bytes()の定義]]を確認すると、

#+BEGIN_QUOTE
pub const fn as_bytes(&self) -> &[u8]
#+END_QUOTE
    
    ~as_bytes()~ の返り値はバイト配列への不変参照になるので、それを可変な変数に格納しても、 ~set_bit()~ でバイト配列には可変アクセスできないのでした。

#+DOWNLOADED: clipboard @ 2020-10-30 09:45:37
#+CAPTION: as_bytes()とas_bytes_mut()の違い
[[file:blog.org_imgs/20201030_094537.png]]
    
*** 解決策
    今回の場合、unsafeなas_bytes_mut()を使用することで、バイト配列への可変参照を取得できます。

    最終的には下記のようなソースにすることで、コンパイルが通ります。

#+CAPTION: 修正したコード
#+BEGIN_SRC rust 
fn main() {
    let mut src = "abc".to_string();
    let mut s = unsafe { src.as_bytes_mut() };
    
    println!("{:08b}", &s[0]);
    set_bit(&mut s, 0);
    println!("↓");
    println!("{:08b}", &s[0]);
}

fn set_bit(bytes: &mut [u8], bit: usize) {
    bytes[bit / 8 as usize] |= 0x80 >> (bit % 8);
}
#+END_SRC

出力結果：

#+caption: 出力結果
#+BEGIN_SRC
01100001
↓
11100001
#+END_SRC

*** まとめ
    Rustを書き始めたときはちんぷんかんぷんでしたが、最近はメモリの状態を意識しながら書くことに慣れてきました。こういうしょうもないエラーもたまにやってしまいますが、トラブルシューティングはかなりスムーズにできるようになってきた気がします。

** DONE 旧ブログの記事をこちらに移行しました                          :Other:
   :PROPERTIES:
   :EXPORT_FILE_NAME: blog-migrated-from-wordpress-to-hugo
   :EXPORT_HUGO_SECTION: /posts/2020/11
   :EXPORT_DATE: 2020-11-10
   :EXPORT_HUGO_CUSTOM_FRONT_MATTER: :toc true
   :END:
   今回はちょっとしたお知らせです。

   随分前からzeroclock.devを始めてはいたのですが、旧サイトの[[https://vivolog.net][ビボログ]]の記事はほったらかしだったのでこっちに持ってきました。

   +XServer高いので早く呪縛から開放されたかった+

   <!--more-->

   当サイトはHugoとgithub.ioの組み合わせで、旧サイトはWordpressだったのでどうしたもんかなーと思い、色々調べてみたら[[https://github.com/SchumacherFM/wordpress-to-hugo-exporter][wordpress-to-hugo-exporter]]というプラグインを使ったらサクッと移行できました。

   ざっと手順はこんな感じ。

#+BEGIN_QUOTE
1. 上記のgithubページからソースを丸ごとzipでダウンロード
2. Wordpress管理画面から、ダウンロードしたzipを読み込んでプラグインを追加
3. ツール＞Export to Hugoで丸ごとダウンロードされる
#+END_QUOTE
   
   いらない画像とかも全部入ってるので、必要なものをピックアップしつつ、マークダウンも若干おかしいので手直ししつつ〜という感じで、そこまで苦労せずに移行できました。

   ただ、記事数が多かったり画像が超多かったりするとメモリ不足で死ぬらしいので、その場合は下記の記事を参考に・・・。

   [[https://randd.kwappa.net/2020/05/17/migrate-wordpress-to-hugo-and-netlify/][WordPressのBlogをHugoとNetlifyに移行する]]

   移行完了したので、旧サイトは多分11月下旬あたりに閉鎖すると思われます。

   
   ということで、今回はちょっとしたお知らせでした。

